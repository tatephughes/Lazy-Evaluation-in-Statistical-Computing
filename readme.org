#+TITLE: How to be Lazy (and improve you Statistical programming while doing it)
#+AUTHOR: Evan Tate Paterson Hughes
#+PROPERTY: header-args :tangle pythoncode.py
#+auto_tangle: t
#+BIBLIOGRAPHY: Bibliography.bib
#+LATEX_HEADER: \usepackage{amsmath,amsfonts,amssymb}

* Ok, I may have lied a little bit

This presentation isn't about you being lazy, it's about your programs being lazy: *Lazy Evaluation*.

* What is Lazy evaluation?

Roughly speaking, we make sure our programs only actually evaluate anything when we absolutely need to.

#+begin_src python :tangle no
  if condition:
    really_hard_computation()
  else:
    really_easy_computation()
#+end_src

* Definition and example

Let ~f~ be some function. The function is 
- *strict* if every expression within is evaluated when ~f~ is evaluated
- *non-strict* (lazy) if at least one of the expressions within ~f~ might not be evaluated upon evaluating ~f~.

** Example

Consider the function ~|~ in python, which can be used for ~Or~ statements. This operator is _not_ lazy!

We can demonstrate this by using booleans with print statements embedded

#+begin_src python :session example :results none
  def bool_func_1():
     print("bool_func_1 was evaluated")
     return True

  def bool_func_2():
     print("bool_func_2 was evaluated")
     return False
#+end_src

** Example (continued)

#+begin_src python :session example :results output
  result = bool_func_1() | bool_func_2()
  print(result)
#+end_src

The ~|~ operator in python is not lazy!

<*<<* Example (continued again)

However, the ~or~ operator is lazy (yes, there is a difference between these two!)

#+begin_src python :session example :results output
  result = bool_func_1() or bool_func_2()
  print(result)
#+end_src

It is often said that the ~or~ operator is /short-circuiting/, while ~|~ is not; what this really means is that ~or~ is lazy!

* Other examples in python

There are other functions in python which are lazy, for example, ~and~ is (but ~&~ is not), and any ~if~ ~else~ statements only compute what is needed.

** User-defined functions

However, the arguments passed into user-defined functions are always evaluated in python;

#+begin_src python :session example :results none
  def my_or_function(bool1,bool2): return bool1 or bool2 
#+end_src

We know ~or~ is lazy, so passing through ~bool_func_1, bool_func_2~ should only evaluate ~bool_func_1~ and then 'short circuit right'?

** User-defined functions (continued)

#+begin_src python :session example :results output
  print(my_or_function(bool_func_1(),bool_func_2()))
#+end_src

the arguments are evaluated as soon as they are passed through a function, before the function is even run!

* Infinite sequences

- We deal a lot with infinite sequences in statistics

- Why can't we represent them fully in code?

- Lazyness provides a solution to this!

** Lazy lists

#+begin_src scala

  val fibs: LazyList[Int] = 0 #:: fibs.scanLeft(1)(_ + _)
  // val fibs: LazyList[Int] = LazyList(<not computed>)

#+end_src

We can take as many as we want; ~fibs~ represents the whole infinite sequence of fibonacci numbers!

#+begin_src scala
  fibs(30)
  // val res0: Int = 832040
#+end_src

or take the first n elements of the list

#+begin_src scala
  fibs.take(30).toLits
  //val res1: List[Int] = List(0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946, 17711, 28657, 46368, 75025, 121393, 196418, 317811, 514229)
#+end_src

** In Statistics

In statistics so many things are infinite sequences MCMC algorithms come to mind in particular.

Imagine code where a fixed sample size is not needed; we can represent infinitely many samples in a variable, and always just pick out however many we may want!

*** MCMC Algorithms

For example, lets take a simple metropolis sampler. For the simple case of a Gaussian target $\pi \sim\mathcal N(0,\Sigma)$ with mean $0$ and variance $\Sigma=M^TM$ where $M_{ij}\sim\mathcal N(0,1)$, and we use the proposal as uncorrelated gaussians, $q_n(x,\cdot)\sim\mathcal N_p(x, \lambda^2 Id)$.


We can construct a metropolis sampler for this as follows;

#+begin_src scala
  import breeze.linalg._
  import breeze.stats.distributions._
  import breeze.stats.distributions.Rand.FixedSeed.randBasis
  import scala.math
  import java.util.concurrent.ThreadLocalRandom
  def rng = ThreadLocalRandom.current()

  def one_MRTH_step(x: DenseVector[Double],
    r: DenseMatrix[Double],
    q: DenseMatrix[Double]
  ): DenseVector[Double] = {

    val proposed_move = x.map((xi:Double) => Gaussian(xi, 0.01/d.toDouble).sample())
    val alpha = 0.5 * ((x.t * (r \ (q.t * x))) - (proposed_move.t * (r \ (q.t * proposed_move))))
    val log_acceptance_prob = math.min(0.0, alpha)
    val u = rng.nextDouble()
    if (math.log(u) < log_acceptance_prob) then proposed_move else x

  }
#+end_src

*** MCMC Algorithms (continued)

Once we've chosen a, initial value, we can the define the rest of the infinite chain using a operation ~LazyList.iterate~ in scala

#+begin_src scala
  LazyList.iterate(x0)((x:DenseVector[Double]) => one_MRTH_step(x,q,r)
#+end_src

*** MCMC Algorithms (continued)

By can, of course, do the usual stuff on this list

[[file:./Scala_source/MHplot.png]]
